---
title: "Japan Family Income and Expenditure Survey, city competition"
author: "Mitsuo Shiota"
date: "2019-04-19"
output: 
  github_document:
    toc: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
Updated: `r Sys.Date()`

I have made [shinyapps.io](https://mitsuoxv.shinyapps.io/jp-household/), based on these data.

Warning: If you can't read Japanese, it would be very difficult for you to follow me in this project of exploring  [e-Stat, Statistics of Japan](https://www.e-stat.go.jp/en). I tried to refer to English pages, but often failed to find them. Even in API, when I set the parameter lang as "E" for English, the response was "statsDataId equal to [0003125169] does not exist". I had to set lang as "J" for Japanese, instead.


## Summary

I hear which city in Japan consumed most dumplings (gyouza in Japanese, and jiaozi in Chinese) per household last year. This is an annual routine news report. In 2020, Hamamatsu-city  came back to the top rank  [(Japanese)](https://www.at-s.com/news/article/economy/shizuoka/858406.html), based on [Family Income and Expenditure Survey](https://www.stat.go.jp/english/data/kakei/) by the Statistics Bureau, Ministry of Internal Affairs and Communications. So I get data from [e-Stat](https://www.e-stat.go.jp/en) by using [estatapi package by yutannihilation](https://github.com/yutannihilation/estatapi/blob/master/README.en.md).

I find that persistent winning items are speciality goods of each city. I list the top earners in 2020. I draw ranks distribution in each city in 2020. And I argue ranks distribution is partly due to total expenditure differences.

```{r libraries, include=FALSE}
library(tidyverse)
library(scales)
```

## Get meta data

I had to register and get appID, following the instructions in [this page (Japanese)](https://www.e-stat.go.jp/api/api-info/api-guide). I use keyring package to use my appID without making it public.

```{r key_set, results="hide"}
keyring::key_set("e-stat")

```
I search around in Family Income and Expenditure Survey, and manage to know the statsDataId of the appropriate table is "0003348239" from [this page (Japanese)](https://www.e-stat.go.jp/stat-search/database?page=1&layout=datalist&toukei=00200561&tstat=000000330001&cycle=7&tclass1=000000330001&tclass2=000000330004&statdisp_id=0003348239&result_page=1&tclass3val=0). As I mentioned in the warning in the top, I failed to set lang = "E", so I set "J" instead.

Look at the structure of the response. It is a list of 6 data frames. estat_getStatsData function, which I will use later, utilizes @code and @name in each data frame, and add @name. In this case, I would like to keep @level in cat01. I make lookup table for cat01, and drop "@" in the column names. I can check which level I should use, and search "ぎょうざ".

```{r get_meta_data, cache=FALSE}
meta_info <- estatapi::estat_getMetaInfo(appId = keyring::key_get("e-stat"),
                               lang = "J",
                               statsDataId = "0003348239")

str(meta_info)

lookup_cat01 <- meta_info$cat01
names(lookup_cat01) <- str_sub(names(lookup_cat01), start = 2L)

lookup_cat01 <- lookup_cat01 %>% 
  rename(cat01_code = code)

lookup_cat01 %>% 
  filter(level == 3)

lookup_cat01 %>% 
  filter(str_detect(name, "ぎょうざ"))

```

## Get data

As the maximum records per GET is set to 100000, I must repeat five times in this case if I GET manually. Fortunately estat_getStatsData function automates this process. I add "level" of cat01, and clean up.

```{r get_data, cache=FALSE}
# get 497447 records
content <- estatapi::estat_getStatsData(
  appId = keyring::key_get("e-stat"),
  lang = "J",
  statsDataId = "0003348239")

# add level column
temp <- lookup_cat01 %>% 
  select(cat01_code, level)

expenditure <- content %>% 
  left_join(temp, by = "cat01_code") %>% 
  mutate(
    year = str_sub(time_code, start = 1L, end = 4L) %>% as.numeric()
  ) %>% 
  rename(city = 地域区分)

```

## Confirm the Hamamatsu-city's victory in dumplings

According to [this page (Japanese)](https://www.stat.go.jp/data/kakei/hyohon.html), the sample numbers per city are approximately 100 except Tokyo (408 samples). If I assume the standard deviation is 30 percent of the mean, the standard error ratio (ratio of standard deviation of mean estimates to the estimated mean) is 3 percent. Table 1-1 in [this page](https://www.stat.go.jp/data/kakei/hyohonkekka.html) publish the standard error ratios in cat01 of level less than 3 in 2013 survey, and the numbers do not contradict my assumption of 3 percent standard error ratio for cat01 of level 5. 

```{r confirm, echo=FALSE}
# 010920070 371 ぎょうざ
top10city <- expenditure %>% 
  filter(cat01_code == "010920070") %>% 
  filter(year == 2020, area_code != "00000") %>% 
  select(city, value) %>% 
  arrange(desc(value)) %>% 
  top_n(10)

top10city

```

The battle between Hamamatsu-city and Utsunomiya-city is not just in 2020, but has a long history. Let us draw all available years of top 10 cities in 2020.

```{r line_chart, echo=FALSE, fig.width=6, fig.width=8}
expenditure %>% 
  filter(cat01_code == "010920070") %>% 
  filter(city %in% top10city$city) %>% 
  ggplot(aes(x = year, y = value, color = fct_reorder2(city, year, value))) +
  geom_line() +
  labs(
    title = "Annual dumpling expenditure", 
    x = NULL, y = "yen per household",
    color = NULL
  )

```
The differences between top 2 and the rest are narrowing.

By the way, these expenditures don't include dumplings you eat at the restaurants.

## Hamamatsu-city regained championship in grilled eel, too

Hamamatsu-city had been the top of eating the grilled eel in 11 years in a row up to 2018. It lost the top position in 2019, and regained it in 2020.

I search eel to get cat01_code. It is "010920010".

```{r eel, echo=FALSE}
lookup_cat01 %>% 
  filter(str_detect(name, "うなぎ"))

```
Next, I rank 52 cities every year in `r lookup_cat01 %>% filter(level == 5) %>% nrow()` items of level 5. 52 cities consist of 47 prefectural capital cities and 5 non-prefectural-capital large cities whose population is more than half million.

```{r area_ranks, echo=FALSE}
# area ranks
area_ranks <- expenditure %>% 
  filter(level == 5) %>% 
  filter(area_code != "00000") %>% 
  group_by(year, cat01_code) %>% 
  mutate(ranks = rank(desc(value), ties.method = "average")) %>% 
  ungroup()

```

I show the top 3 in eel every year.

```{r eel_top3, echo=FALSE}
area_ranks %>% 
  filter(cat01_code == "010920010") %>% 
  filter(ranks <= 3) %>% 
  select(year, city, ranks) %>% 
  spread(key = year, value = city) %>% 
  t()

```


## Persistent victory items are mostly speciality goods

I count the number of cities which get the top rank in 14 years from 2007 to 2020 for each item.

```{r histogram, echo=FALSE, fig.width=6, fig.height=6}
n_top <- area_ranks %>% 
  filter(ranks == 1) %>% 
  group_by(cat01_code) %>% 
  summarize(n_unique_cities = length(unique(city)))

n_top %>% 
  ggplot(aes(x = n_unique_cities)) +
  geom_histogram(binwidth = 1) +
  coord_cartesian(xlim = c(1, 14))

```

```{r n_top_1, echo=FALSE}
n_top_1 <- n_top %>% 
  filter(n_unique_cities == 1)

```
There are `r nrow(n_top_1)` items where one city keeps the top rank. Most of these items match speciality goods in each city.

```{r speciality goods, echo=FALSE}
area_ranks %>% 
  filter(ranks == 1, year == 2020) %>% 
  semi_join(n_top_1, by = "cat01_code") %>% 
  select(cat01_code, `品目分類（2020年改定）`, city) %>% 
  print(n=Inf)

```

## Who are the top rank earners in 2020?

In how many items among `r lookup_cat01 %>% filter(level == 5) %>% nrow()` did each city get the top in 2020?

```{r top_counts, echo=FALSE}
area_ranks %>% 
  filter(ranks == 1, year == 2020) %>% 
  group_by(city) %>% 
  count(sort = TRUE) %>% 
  print(n=Inf)

```

## Ranks distribution in each city in 2020

I draw the histogram that shows each city's ranks of `r lookup_cat01 %>% filter(level == 5) %>% nrow()` items in 2020. Naha-city and other Kyushu cities and Wakayama-city tend to rank low, while Tokyo and other Kanto cities tend to rank high.

```{r histogram2, echo=FALSE, fig.width=10, fig.height=8}
area_ranks %>% 
  filter(year == 2020) %>% 
  ggplot(aes(x = ranks)) +
  geom_histogram(boundary= 0.5, binwidth = 4) +
  facet_wrap(~ city) +
  coord_cartesian(xlim = c(1, 52)) +
  labs(title = "Ranks distribution in 52 cities in 2020")

```
This pattern reflects that total expenditures are high in Kanto, and low in Wakayama-city, Naha-city and other Kyushu cities, partly due to price level differences.

```{r total_expenditure, echo=FALSE, results="hide", fig.width=8, fig.height=10}
expenditure %>% 
  filter(level == 1) %>% 
  select(cat01_code, `品目分類（2020年改定）`) %>% 
  unique()

national <- expenditure %>% 
  filter(cat01_code == "001100000") %>%
  filter(year == 2020, area_code == "00000", cat02_code == "03") %>% 
  select(value) %>%
  as.numeric()

expenditure %>% 
  filter(cat01_code == "001100000") %>% #消費支出
  filter(year == 2020, area_code != "00000") %>% 
  ggplot(aes(x = fct_reorder(city, value), y = value)) +
  geom_hline(yintercept = national,
             color = "white", size = 2) +
  geom_point() +
  annotate("text", x = "37201 高松市", y = national + 100000,
           label = "national mean") +
  scale_y_continuous(labels = comma) +
  coord_flip() +
  labs(
    title = "Total expenditure",
    x = NULL,
    y = "yen per year per household"
  )

```

I draw the map of 47 prefectures by excluding 5 non-capital cities.

```{r jpn_shp, echo=FALSE, results="hide"}
library(NipponMap)
library(sf)

japan_shp <- st_read(system.file("shapes/jpn.shp", package="NipponMap"))

exp_only_capital <- expenditure %>% 
  filter(!area_code %in% c("00000", "14004", "14150", "22004", "27004", "40003")) %>% #全国、川崎市、相模原市、浜松市、堺市、北九州市
  filter(cat01_code == "001100000") %>% #消費支出
  filter(year == 2020) %>% 
  arrange(area_code)

japan_shp %>% 
  ggplot() +
  geom_sf(aes(fill = exp_only_capital$value)) +
  scale_fill_gradient2(low = "#559999", mid = "grey90", high = "#BB650B",
                       midpoint = median(exp_only_capital$value)) +
  labs(fill = "Total expenditure\nyen per year per household") +
  theme_void()

```


```{r save_for_shiny, include=FALSE}
# save expense for Shiny app
expense <- expenditure %>% 
  filter(unit == "円", cat02_code == "03", year >= 2007) %>% 
  rename(cat01 = `品目分類（2020年改定）`)

cities <- expense %>% 
  select(city) %>% 
  unique()

cities %>% 
  write.csv("data/cities.csv", row.names = FALSE)

cities_e <- read_csv("data/cities_e.csv")

expense <- expense %>% 
  left_join(cities_e, by = "city")

saveRDS(expense, file = "data/expense.rds")

```

EOL